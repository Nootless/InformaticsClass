{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7414f869-4ebc-4463-9d4c-196188210d02",
   "metadata": {},
   "source": [
    "### HW 1 - Part 2 - Spam Classifier ###\n",
    "\n",
    "Please rename the file with your \"First_Last_Name_HW1_Part2.ipynb\".<br><br>Please write the relevant code in the respective cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "263cbbba-ca31-4244-81a1-9484cc219928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the modules you will need in completing this part\n",
    "# I have populated the warnings module to avoid unnecessary warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26a5a2b0-be56-4ec7-a4a2-beaf1fbf0308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  class                                            message\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n"
     ]
    }
   ],
   "source": [
    "# Read in the data from 'SMS_Spam.csv' and check\n",
    "# If you want to see what a row of data looks like print(data['message'].loc[9]\n",
    "data = pd.read_csv('sms_spam.csv')\n",
    "print(data.head())\n",
    "# print(data['message'].loc[9])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33153638-f510-483e-8bb0-bfaea85e8d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       go until jurong point, crazy.. available only ...\n",
      "1                           ok lar... joking wif u oni...\n",
      "2       free entry in 2 a wkly comp to win fa cup fina...\n",
      "3       u dun say so early hor... u c already then say...\n",
      "4       nah i don't think he goes to usf, he lives aro...\n",
      "                              ...                        \n",
      "5569    this is the 2nd time we have tried 2 contact u...\n",
      "5570                 will Ã¼ b going to esplanade fr home?\n",
      "5571    pity, * was in mood for that. so...any other s...\n",
      "5572    the guy did some bitching but i acted like i'd...\n",
      "5573                           rofl. its true to its name\n",
      "Name: message, Length: 5574, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert all text in the dataframe column \"message\" to lower case\n",
    "# Check it has been done\n",
    "data['message'] = data['message'].str.lower()\n",
    "print(data['message'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7580a271-b51e-48b9-9576-fbdac34b93d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non alphanumeric characters in the dataframe column \"message\"\n",
    "# Use apply and lambda as shown in examples in lectures\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e8eedc-fa97-4d17-af16-9d28328b8b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the WordNetLemmatizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91c6839c-e1d1-4e35-9bc5-22cacd19f77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatize text in the dataframe column \"message\"\n",
    "# Use apply and lambda as shown in examples in lectures\n",
    "# Check it worked\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a36dacdc-ff0b-4cea-b22a-defffeecff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the TF-IDF vectorizer\n",
    "# Make sure you set the parameter - stop_words='english' \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "290f22d2-6f42-4389-857a-fb91a2f30607",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data in X and y datasets\n",
    "# X will be the 'message' column, y will be the 'class' column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e76a565-1181-43a9-ae6e-0831f153d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "# Set random State = 20 and test_size = 0.15\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01c850ec-a8cb-4f48-b6d7-b3d6f5dfe48c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the train data with the TF-IDF vectorizer and then\n",
    "# Transform train and test data to tfidf matrices\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d27f4ed3-4cba-4cd8-b213-de5fadb03874",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the train and test matrices to dense matrices\n",
    "# Use 'todense()' or 'toarray()'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18dd0873-9fcd-42cd-9690-0c325e0d51dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Multinomial Naive Bayes classifier\n",
    "# Fit a model\n",
    "# Predict on test set\n",
    "# Print the accuracy and confusion matrix\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a38095e-a2a1-4ac1-a789-f39aae835f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is OPTIONAL\n",
    "\n",
    "# Identify the Most Powerful Features using this function\n",
    "# Print the 10 most important features.\n",
    "\n",
    "def get_most_important_features(vectorizer, classifier, n=None):\n",
    "    feature_names = vectorize.get_feature_names_out()\n",
    "    top_features = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "    for coef, feat in top_features:\n",
    "        print(coef, feat)\n",
    "        \n",
    "        \n",
    "# Call the function here \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51945444-22eb-4b79-bbba-4d371616b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data on which you need to predict whether it is ham or spam\n",
    "# There are 6 documents in this list\n",
    "\n",
    "email = [\"Hello George, how about a game of tennis tomorrow?\",\n",
    "         \"freemsg for love birds for free membership use wap link\",\n",
    "         \"We offer free viagra!!! Click here now!!!\",\n",
    "         \"Dear Sara, I prepared the annual report.\",\n",
    "         \"Hi David, will we go for cinema tonight?\",\n",
    "         \"Free entry EPL cup tickets!!!\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0097766-bd9e-48cb-a393-a274f9195b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usually you will need to apply all the preprocessing steps you did on the original dat also on this\n",
    "# To keep it simple - Create a new list which has these 6 documents but just converted to lower case\n",
    "# Check it is done\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4baa9f86-8edb-4bbb-8915-bf400016d3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the same TF-IDF object you fitted the train data with and transform the new list\n",
    "# Print predictions using the earlier fitted multinomial model \n",
    "# If you get - ['ham','spam','spam','ham','ham','spam'] then it would be 100% correct\n",
    "# Not critical that you get 100% results - more important that it works\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d7d4ea-20f1-4e82-8a20-8ed00d41230e",
   "metadata": {},
   "source": [
    "#### Questions - Please answer in a Markdown Cell below ####\n",
    "\n",
    "1. What were your challenges in completing this part of the HW?\n",
    "\n",
    "2. What were your biggest learnings?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
